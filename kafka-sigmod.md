# kafka
Kafka是一种高吞吐量的分布式发布订阅消息系统
## 消息队列
消费数据”那里这么讲更容易理解：
把每个partition比作一碗饭，每个consumer比作一个人。
- 可以出现一个人吃同时多碗饭的情况。（吃货）
- 不能出现多个人吃一碗饭的情况。（不能抢饭吃）
- 如果人比多饭碗，那就得有人饿着。
- 一人一碗饭，刚好。
## 发布订阅模式
topic队列
分区（Partition） -不同主题
offset-分区消息里的偏移量

# 并行处理
作者：大数据小编
链接：https://zhuanlan.zhihu.com/p/359309707
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。

众所周知，对于计算密集型或数据密集型这样需要计算量比较大的工作，并行计算或分而治之是解决这一类问题非常有效的手段。在这个手段中比较关键的部分是，如何对一个已有任务的划分，或者说如何对计算资源进行合理分配。举例说明，上学期间老师有时会找同学来协助批阅考试试卷。假如卷子里面一共有ABC三个题，那么同学可能会有如下分工协作方式。
- 方式一：将所有试卷的三个题分别交给不同的人来批阅。这种方式，每个批阅的同学批自己负责的题目后就可以把试卷传给下一个批阅同学，从而形成一种流水线的工作效果。因为总共只有三道题目，这种流水线的协作方式会随着同学数量的增加而难以继续扩展。
- 方式二：分工方式一的扩展，同一题目允许多个同学来共同批阅，比如A题目由两个同学共同批阅，B题目由三个同学批阅，C题目只由一个同学批阅。这时候我们就需要考虑怎样进一步的对计算任务做划分。比如，可以把全部同学分成三组，第一组负责A题目，第二个组负责B题目第三个组负责C。第一个组的同学可以再次再组内进行分工，比如A组里第一个同学批一半的卷子，第二个同学批另一半卷子。他们分别批完了之后，再将自己手里的试卷传递给下一个组。

像上述按照试卷内题目进行划分，以及讲试卷本身进行划分，就是所谓的计算的并行性和数据并行性。
[![5elvmd.png](https://z3.ax1x.com/2021/10/12/5elvmd.png)](https://imgtu.com/i/5elvmd)
我们可以用上面有向无环图来表示这种并行性。在图中，批阅A题目的同学，假设还承担了一些额外任务，比如把试卷从老师的办公室拿到批阅试卷的地点；负责C题的同学也额外任务，就是等所有同学把试卷批完后，进行总分的统计和记录上交的工作。据此，可以把图中所有的节点划分为三个类别。第一个类别是Source，它们负责获取数据（拿试卷）；第二类是数据处理节点，它们大多时候不需要和外部系统打交道；最后一个类别负责将整个计算逻辑写到某个外部系统（统分并上交记录）。这三类节点分别就是Source节点、Transformation节点和Sink节点。DAG图中，节点表示计算，节点之间的连线代表计算之间的依赖。

# 分布式系统
## 难点
- end to end consistency端到端一致性
最终一致性
A扣钱成功，调用B加钱接口失败。
A扣钱成功，调用B加钱接口虽然成功，但获取最终结果时网络异常引起超时。
A扣钱成功，B加钱失败，A想回滚扣的钱，但A机器down机。
- 解决方案

强一致性，分布式事务，但落地太难且成本太高，后文会具体提到。最终一致性，主要是用“记录”和“补偿”的方式。在做所有的不确定的事情之前，先把事情记录下来，然后去做不确定的事情，结果可能是：成功、失败或是不确定，“不确定”（例如超时等）可以等价为失败。成功就可以把记录的东西清理掉了，对于失败和不确定，可以依靠定时任务等方式把所有失败的事情重新搞一遍，直到成功为止。回到刚才的例子，系统在A扣钱成功的情况下，把要给B“通知”这件事记录在库里（为了保证最高的可靠性可以把通知B系统加钱和扣钱成功这两件事维护在一个本地事务里），通知成功则删除这条记录，通知失败或不确定则依靠定时任务补偿性地通知我们，直到我们把状态更新成正确的为止。整个这个模型依然可以基于RPC来做，但可以抽象成一个统一的模型，基于消息队列来做一个“企业总线”。具体来说，本地事务维护业务变化和通知消息，一起落地（失败则一起回滚），然后RPC到达broker，在broker成功落地后，RPC返回成功，本地消息可以删除。否则本地消息一直靠定时任务轮询不断重发，这样就保证了消息可靠落地broker。broker往consumer发送消息的过程类似，一直发送消息，直到consumer发送消费成功确认。我们先不理会重复消息的问题，通过两次消息落地加补偿，下游是一定可以收到消息的。然后依赖状态机版本号等方式做判重，更新自己的业务，就实现了最终一致性。
## 消息队列设计思路
一般来讲，设计消息队列的整体思路是先build一个整体的数据流,例如producer发送给broker,broker发送给consumer,consumer回复消费确认，broker删除/备份消息等。
一般来讲，设计消息队列的整体思路是先build一个整体的数据流,例如producer发送给broker,broker发送给consumer,consumer回复消费确认，broker删除/备份消息等。利用RPC将数据流串起来。然后考虑RPC的高可用性，尽量做到无状态，方便水平扩展。之后考虑如何承载消息堆积，然后在合适的时机投递消息，而处理堆积的最佳方式，就是存储，存储的选型需要综合考虑性能/可靠性和开发维护成本等诸多因素。为了实现广播功能，我们必须要维护消费关系，可以利用zk/config server等保存消费关系。在完成了上述几个功能后，消息队列基本就实现了。然后我们可以考虑一些高级特性，如可靠投递，事务特性，性能优化等。

- 保证消息处理顺序


## 思路
先介绍一致性和完整性
    - 完整性：保证流处理应用不会产生不完整（partial）结果，尤其是在数据迟到、时间乱序的情况。
    - 一致性：一个消息只被处理一次，造成一次效果
    - EOMP:Effective once msg processing(应该翻成有效一次性处理?)
        - 幂等：一个相同的操作, 无论重复多少次, 造成的效果都和只操作一次相等。不幂等的操作转化为幂等操作是end to end consistency的关键之一
        - 非确定性计算：相同的input必得到相同的output, 则是一个确定性(deterministic)。非确定性计算一般会导致不幂等的操作, 比如我们如果要把上边例子里的keyvalue存在数据库里, 重复处理多少次同一个msg, 我们就会重复的插入多少条数据(因为key里的时间戳字符串不同);
        所以支持非确定业务计算的同时, 还能在容错（机器挂了,网络链接断开...）的情况下达成端到端一致性, 是流系统的大难题。
      实现正确性的基石是精确一次处理语义:Exactly once
    
    - 经典错误四张图
        最终一致性
        A扣钱成功，调用B加钱接口失败。
        A扣钱成功，调用B加钱接口虽然成功，但获取最终结果时网络异常引起超时。
        A扣钱成功，B加钱失败，A想回滚扣的钱，但A机器down机。

